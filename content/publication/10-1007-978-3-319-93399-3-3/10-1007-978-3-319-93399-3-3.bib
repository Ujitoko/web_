@inproceedings{10.1007/978-3-319-93399-3_3,
 abstract = {Providing vibrotactile feedback that corresponds to the state of the virtual texture surfaces allows users to sense haptic properties of them. However, hand-tuning such vibrotactile stimuli for every state of the texture takes much time. Therefore, we propose a new approach to create models that realize the automatic vibrotactile generation from texture images or attributes. In this paper, we make the first attempt to generate the vibrotactile stimuli leveraging the power of deep generative adversarial training. Specifically, we use conditional generative adversarial networks (GANs) to achieve generation of vibration during moving a pen on the surface. The preliminary user study showed that users could not discriminate generated signals and genuine ones and users felt realism for generated signals. Thus our model could provide the appropriate vibration according to the texture images or the attributes of them. Our approach is applicable to any case where the users touch the various surfaces in a predefined way.},
 address = {Cham},
 author = {Ujitoko, Yusuke
and Ban, Yuki},
 booktitle = {Haptics: Science, Technology, and Applications},
 editor = {Prattichizzo, Domenico
and Shinoda, Hiroyuki
and Tan, Hong Z.
and Ruffaldi, Emanuele
and Frisoli, Antonio},
 isbn = {978-3-319-93399-3},
 pages = {25--36},
 publisher = {Springer International Publishing},
 title = {Vibrotactile Signal Generation from Texture Images or Attributes Using Generative Adversarial Network},
 year = {2018}
}

